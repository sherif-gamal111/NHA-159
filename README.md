# NHAâ€‘159 â€” Realâ€‘Time Traffic Data Engineering Project ğŸš¦

## ğŸš€ Project Overview  
This project ingests, processes, and transforms UK traffic data into a clean, analyticsâ€‘ready data warehouse following a **Bronze â†’ Silver â†’ Gold** multiâ€‘layered architecture. The resulting data model supports downstream reporting and visualization using tools like Powerâ€¯BI â€” making insights from raw traffic data accessible to analysts and decisionâ€‘makers.  

Key strengths & deliverables:  
- Full end-to-end data pipeline: raw ingestion, cleaning, schema design, and loading.  
- Star schema modeling for efficient querying and reporting.  
- Clean, surrogateâ€‘keyed data with enforced referential integrity and data type validation.  
- A reproducible workflow thatâ€™s easy to understand and extend.  

---

## ğŸ“ Repository Structure  
```
NHA-159/
â”‚
â”œâ”€â”€ Data Warehouse/ â€” SQL schema and data warehouse artifacts
â”œâ”€â”€ Data Sets/ â€” Raw and intermediate datasets (raw, cleaned CSVs, etc.)
â”œâ”€â”€ Data Analysis/ â€” Notebooks & scripts for data profiling, cleaning, transformation
â”œâ”€â”€ Scripts.zip â€” Backup of cleaning or ETL scripts
â”œâ”€â”€ Assets.zip â€” Architecture diagrams, data model visuals, starâ€‘schema diagram, etc.
â””â”€â”€ README.md â€” This file
```
---

## ğŸ› ï¸ Tools & Technologies  

| Tool / Technology | Purpose |
|------------------|---------|
| **Python**        | Data cleaning, transformation, and preprocessing of raw traffic data |
| **Tâ€‘SQL / SQL Server** | Storage, schema creation, and modeling of processed data |
| **Powerâ€¯BI**      | Reporting and visualization of cleaned, aggregated traffic data |
| **Git & GitHub** | Version control, collaboration, and documentation management |

---

## ğŸ”„ Project Workflow  

1. **Raw data ingestion** â†’ collect raw traffic data files under `Data Sets/`.  
2. **Data cleaning & normalization** â†’ use Python scripts/notebooks under `Data Analysis/` to clean, dedupe, enforce data types, and prepare for loading.  
3. **Schema design & data loading** â†’ use the SQL scripts in `Data Warehouse/` to create starâ€‘schema tables and load cleaned data.  
4. **Reporting / Visualization** â†’ connect the warehouse data to Power BI dashboards for analysis and insights.  

---

## ğŸ“Š Data Model (Silver / Gold Layer)  

**Core tables and dimensions**:

- `Traffic` â€” Fact table with traffic events (keyed by `Traffic_id`)  
- `Road` â€” Road metadata (keyed by `Road_id`)  
- `Region` â€” Region metadata (keyed by `Region_id`)  
- `LocalAuthority` â€” Local authority metadata (keyed by `Local_authority_id`)  
- `Location` â€” Geographic coordinates and location metadata (keyed by `Location_id`)  
- `Date` â€” Date dimension for timeâ€‘based analysis (keyed by `Date_id`)  

Relationships:  
- `Traffic.Road_id â†’ Road.Road_id`  
- `Traffic.Region_id â†’ Region.Region_id`  
- `Traffic.Local_authority_id â†’ LocalAuthority.Local_authority_id`  
- `Traffic.Location_id â†’ Location.Location_id`  
- `Traffic.Date_id â†’ Date.Date_id`  

This design enables efficient querying, timeâ€‘series analysis, and integration with BI tools.

---

## âœ… Data Cleaning Highlights  

- Duplicate records removed  
- Added surrogate primary keys for dimension & fact tables  
- Validated & standardized data types (dates, numeric, strings)  
- Enforced referential integrity for all foreignâ€‘key relationships  
- Prepared clean CSVs ready for schema loading  

---

## ğŸ“Š Visual Assets  

Youâ€™ll find diagrams, workflow visuals, and starâ€‘schema illustrations in `Assets.zip`. These provide an intuitive view of data flow, architecture, and entity relationships for better understanding and documentation.  

---

## ğŸ§  Key Learnings & Takeaways  

- How to build a multiâ€‘layer data pipeline (Bronze â†’ Silver â†’ Gold) from raw data ingestion to analyticsâ€‘ready warehouse.  
- Effective data cleaning and normalization techniques when dealing with real-world noisy traffic datasets.  
- Star schema modeling and dimensional design for building BIâ€‘ready data structures.  
- End-to-end integration: ingestion â†’ cleaning â†’ modeling â†’ visualization.  

---

## ğŸ‘¥ Contributors  

| Name | Role / Responsibility |
|------|-----------------------|
| Osama Hegazy           | SQL & Data Cleaning  |  
| Mohamed Nasr Aldin     | Data Cleaning         |  
| Sherif Gamal           | SQL Modeling          |  
| Ahmed Salama           | Power BI Reporting    |  
| Zakaria Yehia          | Power BI Reporting    |  
| Sara Hisham            | Power BI Reporting    |  
| Yousef Ahmed           | Power BI Reporting    |  

---

## ğŸ”® Next Steps / Future Improvements  

- Integrate workflow orchestration (e.g. add Apache Airflow or Azure Data Factory) to automate the pipeline.  
- Enable incremental data refresh for continuous data updates.  
- Add monitoring, logging, and alerting to track pipeline health & data quality over time.  
- Potentially migrate to a cloud-based data warehouse or improve scalability.  

---

## ğŸ“„ License & Usage  

This project is open for educational and demonstration purposes. Feel free to explore, fork, and adapt â€” but please attribute the original authors.

---

## ğŸ”— Contact  

For questions, collaboration requests, or suggestions â€” open an issue or reach out via GitHub.  

---
